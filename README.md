# youtube_to_summary
Pipeline to generate summaries of youtube videos, using [Whisper-Small](https://huggingface.co/openai/whisper-small) for transcription, and [BART-LARGE-XSUM](https://huggingface.co/knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM) for summarisation. BART has been finetuned on the popular [CNN/Daily Mail](https://huggingface.co/datasets/cnn_dailymail) Dataset, as it lends itself to summarisation tasks. Initially, we attempted to fine-tune GPT-2 for the summarisation task, but found it had poor performance: being a generative transfotmer, it generates words one-by-one, (extractive summarisation) whereas BART can generate at the sentence level (using abstractive summarisation). For more info on choice of summarisation model, see [this article](https://www.width.ai/post/bart-text-summarization). We use the HuggingFace `Transformers` libary to abstract some of the PyTorch code using the `pipeline` submodule.

### Warning
For some instances of google colab, the [yt-dlp](https://github.com/yt-dlp/yt-dlp) package may not work. This is an issue with the package, and cannot be resolved at this time. If you encouter this, I reccomend trying the [pytube]([https://github.com/pytube](https://github.com/pytube/pytube)) package instead.
